import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from models.pointnet2_sem_seg import get_model, get_loss
from core.dataset import TunnelDataset


def train():
    # ==========================================================
    # 1. é’ˆå¯¹ RTX 4060 & 32æ ¸ CPU çš„ä¸“é¡¹é…ç½®
    # ==========================================================
    data_root = "data/processed"
    batch_size = 32  # 8GB æ˜¾å­˜å»ºè®®ä» 32 å¼€å§‹ï¼Œå¦‚æœæŠ¥é”™å†è°ƒå› 16
    epochs = 50
    learning_rate = 0.001

    # å¯ç”¨åº•å±‚ç®—æ³•è‡ªåŠ¨ä¼˜åŒ–
    torch.backends.cudnn.benchmark = True

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  æ£€æµ‹åˆ°ç¡¬ä»¶åŠ é€Ÿ: {torch.cuda.get_device_name(0)}")
    print(f"ğŸš€ æ ¸å¿ƒé…ç½®: Batch Size={batch_size}, Device={device}")

    # 2. åŠ è½½æ•°æ®é›†
    train_dataset = TunnelDataset(data_root=data_root, num_points=4096, block_size=3.0, train=True)

    # ä¼˜åŒ–ç‚¹ï¼šWindows ä¸‹ 32æ ¸ CPU å»ºè®®è®¾ç½® num_workers ä¸º 4 æˆ– 8
    # pin_memory=True èƒ½æ˜¾è‘—åŠ å¿«å†…å­˜åˆ°æ˜¾å­˜çš„ä¼ è¾“
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=8,
        pin_memory=True,
        drop_last=True  # ä¸¢å¼ƒæœ€åä¸æ»¡è¶³ Batch çš„æ•°æ®ï¼Œä¿æŒè®¡ç®—æ­¥é•¿ä¸€è‡´
    )

    # 3. åˆå§‹åŒ–æ¨¡å‹ä¸æŸå¤±å‡½æ•°
    model = get_model(num_classes=2).to(device)
    criterion = get_loss().to(device)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # 4. åˆå§‹åŒ– AMP (è‡ªåŠ¨æ··åˆç²¾åº¦) ç¼©æ”¾å™¨
    scaler = torch.cuda.amp.GradScaler()

    # 5. è®­ç»ƒå¾ªç¯
    os.makedirs("checkpoints", exist_ok=True)
    best_loss = float('inf')

    print("å¼€å§‹è®­ç»ƒ...")
    for epoch in range(epochs):
        model.train()
        total_loss = 0.0

        for batch_idx, (points, labels) in enumerate(train_loader):
            points, labels = points.to(device), labels.to(device)
            optimizer.zero_grad()

            # æ•°æ®è½¬ç½® [B, N, 6] -> [B, 6, N]
            points = points.transpose(2, 1)

            # --- AMP è‡ªåŠ¨æ··åˆç²¾åº¦æ ¸å¿ƒé€»è¾‘ ---
            with torch.cuda.amp.autocast():
                predictions = model(points)
                loss = criterion(predictions, labels)

            # ç¼©æ”¾æŸå¤±å¹¶å›ä¼ 
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            total_loss += loss.item()

            if batch_idx % 5 == 0:
                print(f"Epoch [{epoch + 1}/{epochs}] Step [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}")

        avg_loss = total_loss / len(train_loader)
        print(f"ğŸ Epoch {epoch + 1} ç»“æŸï¼Œå¹³å‡ Loss: {avg_loss:.4f}")

        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), "checkpoints/best_pipe_model.pth")
            print(f"ğŸ’¾ æƒé‡å·²æ›´æ–°: checkpoints/best_pipe_model.pth")


if __name__ == "__main__":
    train()