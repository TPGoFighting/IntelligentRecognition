import sys
import os
import numpy as np
import pyvista as pv
import open3d as o3d
import pyransac3d as pyrsc
import torch
from pyvistaqt import QtInteractor
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout,
                             QHBoxLayout, QPushButton, QTextEdit, QLabel, QFileDialog)

# ç¡®ä¿èƒ½å¯¼å…¥ä½ å®šä¹‰çš„æ¨¡å‹
from models.pointnet2_sem_seg import get_model


class TunnelDetectorApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Intelligent Recognition - éš§é“å¤šç®¡é“è¯†åˆ«ç³»ç»Ÿ V5.5")
        self.setGeometry(100, 100, 1100, 750)
        self.raw_points = None
        self.raw_normals = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # å¤§ç‚¹äº‘å¤„ç†é…ç½®
        self.max_points = 10000000  # æœ€å¤§å¤„ç†ç‚¹æ•°ï¼Œè¶…è¿‡ä¼šè‡ªåŠ¨é™é‡‡æ ·
        self.voxel_size = 0.05  # åˆå§‹ä½“ç´ é™é‡‡æ ·å¤§å°
        self.max_windows = 200  # æœ€å¤§æ»‘çª—æ•°é‡ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        self.render_point_limit = 50000  # æ¸²æŸ“ç‚¹æ•°é™åˆ¶ï¼Œé˜²æ­¢å›¾å½¢å´©æºƒ

        self.init_ui()

    def init_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QHBoxLayout(central_widget)

        control_panel = QWidget()
        control_panel.setFixedWidth(240)
        control_layout = QVBoxLayout(control_panel)

        self.btn_load = QPushButton("ğŸ“‚ 1. å¯¼å…¥éš§é“ç‚¹äº‘")
        self.btn_load.setMinimumHeight(40)
        self.btn_load.setStyleSheet("background-color: #2196F3; color: white; font-weight: bold;")

        self.btn_detect = QPushButton("ğŸš€ 2. å¯åŠ¨æ™ºèƒ½è¯†åˆ«")
        self.btn_detect.setMinimumHeight(50)
        self.btn_detect.setStyleSheet("background-color: #4CAF50; color: white; font-weight: bold;")

        # ã€ä¿®å¤ç‚¹ã€‘ï¼šç¡®ä¿è¿™é‡Œçš„åå­—ä¸ä¸‹æ–¹å®šä¹‰çš„ä¸€è‡´
        self.btn_load.clicked.connect(self.load_real_point_cloud)
        self.btn_detect.clicked.connect(self.run_intelligent_inference)

        control_layout.addWidget(QLabel("<h3 style='color:#333;'>ç³»ç»Ÿæ“ä½œå°</h3>"))
        control_layout.addWidget(self.btn_load)
        control_layout.addWidget(QLabel("<hr>"))
        control_layout.addWidget(self.btn_detect)
        control_layout.addStretch()

        right_panel = QWidget()
        right_layout = QVBoxLayout(right_panel)
        self.plotter = QtInteractor(right_panel)
        self.plotter.set_background("#1e1e1e")
        self.log_window = QTextEdit()
        self.log_window.setReadOnly(True)
        self.log_window.setFixedHeight(160)
        self.log_window.setStyleSheet("background-color: #000000; color: #00FF00; font-family: Consolas;")

        right_layout.addWidget(self.plotter.interactor)
        right_layout.addWidget(self.log_window)
        main_layout.addWidget(control_panel)
        main_layout.addWidget(right_panel)
        self.log("ç³»ç»Ÿå°±ç»ªã€‚")

    def log(self, message):
        self.log_window.append(f"> {message}")
        self.log_window.verticalScrollBar().setValue(self.log_window.verticalScrollBar().maximum())
        QApplication.processEvents()

    def load_real_point_cloud(self):
        try:
            file_name, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹©ç‚¹äº‘æ–‡ä»¶", "", "Point Cloud Files (*.ply *.pcd)")
            if not file_name:
                return

            self.log(f"æ­£åœ¨åŠ è½½ç‚¹äº‘æ–‡ä»¶: {os.path.basename(file_name)}")

            # è¯»å–ç‚¹äº‘
            pcd = o3d.io.read_point_cloud(file_name)
            if len(pcd.points) == 0:
                self.log("[é”™è¯¯] ç‚¹äº‘æ–‡ä»¶ä¸ºç©º")
                return

            raw_points = np.asarray(pcd.points)
            self.log(f"åŸå§‹ç‚¹æ•°: {len(raw_points)}")

            # è‡ªåŠ¨é™é‡‡æ ·ï¼šå¦‚æœç‚¹æ•°è¶…è¿‡é™åˆ¶ï¼Œå¢åŠ ä½“ç´ å¤§å°
            voxel_size = self.voxel_size
            if len(raw_points) > self.max_points:
                self.log(f"ç‚¹äº‘è¿‡å¤§ï¼Œè‡ªåŠ¨é™é‡‡æ ·...")
                # æ ¹æ®ç‚¹æ•°è°ƒæ•´ä½“ç´ å¤§å°
                ratio = self.max_points / len(raw_points)
                voxel_size = self.voxel_size * (1.0 / ratio) ** (1/3)  # ä½“ç§¯ç¼©æ”¾
                voxel_size = max(voxel_size, 0.01)  # æœ€å°ä½“ç´ å¤§å°
                self.log(f"è°ƒæ•´ä½“ç´ å¤§å°: {voxel_size:.3f}")

            # é™é‡‡æ ·ä»¥æé«˜å¤„ç†é€Ÿåº¦
            if voxel_size > 0:
                pcd = pcd.voxel_down_sample(voxel_size=voxel_size)
                self.log(f"é™é‡‡æ ·åç‚¹æ•°: {len(pcd.points)}")

            self.raw_points = np.asarray(pcd.points)
            # ä¿å­˜æ³•çº¿ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if pcd.has_normals():
                self.raw_normals = np.asarray(pcd.normals)
            else:
                self.raw_normals = None

            # æ¸²æŸ“ç‚¹äº‘ï¼ˆé™åˆ¶æ¸²æŸ“ç‚¹æ•°ä»¥é˜²æ­¢å›¾å½¢å´©æºƒï¼‰
            render_points = self.raw_points
            if len(render_points) > self.render_point_limit:
                indices = np.random.choice(len(render_points), self.render_point_limit, replace=False)
                render_points = render_points[indices]
                self.log(f"æ¸²æŸ“ç‚¹æ•°é™åˆ¶ä¸º: {self.render_point_limit}")

            self.plotter.clear()
            self.plotter.add_mesh(pv.PolyData(render_points), color="white", point_size=1, name="scene", opacity=0.3)
            self.plotter.reset_camera()
            self.log(f"âœ… ç‚¹äº‘è½½å…¥æˆåŠŸï¼Œå¤„ç†ç‚¹æ•°: {len(self.raw_points)}")

        except Exception as e:
            self.log(f"[é”™è¯¯] åŠ è½½ç‚¹äº‘å¤±è´¥: {str(e)}")
            import traceback
            self.log(traceback.format_exc())

    def run_intelligent_inference(self):
        """æ ¸å¿ƒæ¨ç†é€»è¾‘ï¼šä¿®å¤äº†æ»‘çª—è¶Šç•Œå’Œ API è­¦å‘Š"""
        if self.raw_points is None:
            self.log("[é”™è¯¯] æœªè½½å…¥æ•°æ®")
            return

        model_path = "checkpoints/best_pipe_model.pth"
        if not os.path.exists(model_path):
            self.log("[é”™è¯¯] æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶")
            return

        # 1. åŠ è½½ AI æ¨¡å‹
        model = get_model(num_classes=3).to(self.device)  # ä¸‰åˆ†ç±»ï¼šç®¡é“(2)ã€éš§é“å£(1)ã€å…¶ä»–èƒŒæ™¯(0)
        state_dict = torch.load(model_path, map_location=self.device, weights_only=True)
        model.load_state_dict(state_dict)
        model.eval()

        # 2. é¢„å¤„ç†
        self.log("é¢„å¤„ç†ï¼šé™é‡‡æ ·ä¸æ³•å‘è®¡ç®—...")
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(self.raw_points)

        # å¦‚æœåŸå§‹æ³•çº¿å­˜åœ¨ï¼Œä½¿ç”¨å®ƒä»¬
        if self.raw_normals is not None:
            pcd.normals = o3d.utility.Vector3dVector(self.raw_normals)
            self.log("ä½¿ç”¨ç‚¹äº‘æ–‡ä»¶ä¸­çš„æ³•çº¿ä¿¡æ¯")
        else:
            self.log("ç‚¹äº‘æ–‡ä»¶ä¸­æ— æ³•çº¿ä¿¡æ¯ï¼Œé‡æ–°è®¡ç®—æ³•çº¿")

        downpcd = pcd.voxel_down_sample(voxel_size=0.05)

        # å¦‚æœä¸‹é‡‡æ ·åæ²¡æœ‰æ³•çº¿ï¼Œåˆ™è®¡ç®—æ³•çº¿
        if not downpcd.has_normals():
            downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.15, max_nn=30))

        points = np.asarray(downpcd.points)
        normals = np.asarray(downpcd.normals)

        # 3. æ»‘çª—æ¨ç†
        self.log("AI æ­£åœ¨æ‰«æéš§é“ (GPU åŠ é€Ÿä¸­)...")
        block_size, stride = 3.0, 1.5
        all_labels = np.zeros(len(points))
        counts = np.zeros(len(points))
        xyz_min, xyz_max = points.min(0), points.max(0)

        # è®¡ç®—æ»‘çª—èŒƒå›´ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        z_range = xyz_max[2] - xyz_min[2]
        num_windows = int(np.ceil(z_range / stride))

        # è‡ªåŠ¨è°ƒæ•´æ­¥é•¿ï¼Œé™åˆ¶çª—å£æ•°é‡
        if num_windows > self.max_windows:
            old_stride = stride
            stride = max(z_range / self.max_windows, block_size * 0.8)  # ç¡®ä¿æœ‰é‡å 
            num_windows = int(np.ceil(z_range / stride))
            self.log(f"çª—å£æ•°è¿‡å¤š ({num_windows})ï¼Œè°ƒæ•´æ­¥é•¿: {old_stride:.2f} â†’ {stride:.2f}")

        # ç”Ÿæˆçª—å£ä¸­å¿ƒåˆ—è¡¨
        z_centers = np.linspace(xyz_min[2] + block_size/2, xyz_max[2] - block_size/2, num_windows)

        self.log(f"æ»‘çª—é…ç½®: {num_windows} ä¸ªçª—å£, æ­¥é•¿ {stride:.2f}m, åŒºå—å¤§å° {block_size:.1f}m")

        processed_windows = 0
        for i, z in enumerate(z_centers):
            try:
                # è¿›åº¦æ›´æ–°
                if i % 10 == 0 or i == num_windows - 1:
                    self.log(f"  è¿›åº¦: {i+1}/{num_windows} çª—å£ ({(i+1)*100/num_windows:.1f}%)")

                mask = (points[:, 2] >= z - block_size/2) & (points[:, 2] < z + block_size/2)
                idx = np.where(mask)[0]

                if len(idx) < 1024:
                    continue

                # é‡‡æ ·å›ºå®šç‚¹æ•°
                if len(idx) >= 4096:
                    sel = np.random.choice(idx, 4096, replace=False)
                else:
                    sel = np.random.choice(idx, 4096, replace=True)

                # ä¸­å¿ƒåŒ–å¹¶æå–ç‰¹å¾
                block_pts = points[sel] - points[sel].mean(0)
                block_feat = np.hstack((block_pts, normals[sel]))

                # æ¨ç†
                input_tensor = torch.FloatTensor(block_feat).unsqueeze(0).transpose(2, 1).to(self.device)
                with torch.no_grad():
                    device_type = 'cuda' if self.device.type == 'cuda' else 'cpu'
                    with torch.amp.autocast(device_type):
                        pred = model(input_tensor)
                        pred_label = torch.argmax(pred, dim=2).cpu().numpy()[0]

                # ç»Ÿè®¡ç®¡é“ç±»åˆ«(2)çš„æŠ•ç¥¨æ•°
                all_labels[sel] += (pred_label == 2).astype(np.int32)
                counts[sel] += 1
                processed_windows += 1

            except Exception as e:
                self.log(f"âš ï¸  çª—å£ {i} å¤„ç†å¤±è´¥: {str(e)}")
                continue

        self.log(f"æ»‘çª—æ¨ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {processed_windows}/{num_windows} ä¸ªçª—å£")

        # 4. åç»­ RANSAC å¤„ç†... (ä¿æŒåŸæ ·)

        # 4. ã€ç¡¬æ ¸å‡çº§ã€‘å¤šç›®æ ‡ RANSAC è¿­ä»£æå–
        self.log("AI æ¨ç†å®Œæˆã€‚å¼€å§‹æ‰§è¡Œå¤šç›®æ ‡å‡ ä½•æå–...")
        self.plotter.remove_actor("scene")  # éšè—èƒŒæ™¯
        self.plotter.add_mesh(pv.PolyData(self.raw_points), color="#404040", point_size=1, opacity=0.1, name="bg")

        # è®¡ç®—ç®¡é“ç‚¹ï¼šåŸºäºæŠ•ç¥¨ç»“æœï¼Œå½“ç®¡é“ç±»åˆ«ï¼ˆ2ï¼‰çš„æŠ•ç¥¨æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼æ—¶è®¤ä¸ºæ˜¯ç®¡é“
        valid_mask = counts > 0
        if not np.any(valid_mask):
            self.log("[é”™è¯¯] æ²¡æœ‰æœ‰æ•ˆçš„æ¨ç†ç‚¹")
            return

        # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼ä»¥æé«˜å¬å›ç‡ï¼šä»0.2é™åˆ°0.1
        pipe_mask = (all_labels[valid_mask] / counts[valid_mask] > 0.1)
        pipe_points = points[valid_mask][pipe_mask]

        if len(pipe_points) == 0:
            self.log("AIæœªæ£€æµ‹åˆ°ä»»ä½•ç®¡é“")
            return

        self.log(f"AIæ£€æµ‹åˆ°{len(pipe_points)}ä¸ªå€™é€‰ç®¡é“ç‚¹")

        found_pipes_count = 0
        remaining_points = pipe_points.copy()

        # å¾ªç¯æå–ï¼Œç›´åˆ°å‰©ä½™ç‚¹æ•°ä¸è¶³ä»¥æ„æˆä¸€æ ¹ç®¡
        while len(remaining_points) > 200:
            # ä½¿ç”¨ç®€å•åœ†æŸ±æ‹Ÿåˆç®—æ³•ï¼ˆpyransac3dæœ‰bugï¼‰
            # å‡è®¾ç®¡é“æ²¿Zè½´æ–¹å‘
            center_xy = remaining_points[:, :2].mean(axis=0)
            radial_distances = np.linalg.norm(remaining_points[:, :2] - center_xy, axis=1)
            radius = np.median(radial_distances)
            center_z = remaining_points[:, 2].mean()
            center = np.array([center_xy[0], center_xy[1], center_z])
            axis = np.array([0, 0, 1])

            # è®¡ç®—å†…ç‚¹
            threshold = 0.08
            distances_to_surface = np.abs(radial_distances - radius)
            inliers = np.where(distances_to_surface < threshold)[0]

            # ç‰©ç†è§„åˆ™è¿‡æ»¤ï¼šç®¡é“åŠå¾„åº”åœ¨ 0.15m - 0.8m ä¹‹é—´
            if 0.15 < radius < 0.8 and len(inliers) > 50:
                found_pipes_count += 1
                current_pipe_pts = remaining_points[inliers]

                # æ¸²æŸ“æ¯ä¸€æ ¹ç®¡é“
                self.add_pipe_to_view(current_pipe_pts, center, axis, radius, found_pipes_count)
                self.log(f"âœ… æå–ç®¡é“ {found_pipes_count}: åŠå¾„ {radius:.3f}m")

                # ä»å€™é€‰æ± ä¸­ç§»é™¤è¿™æ ¹ç®¡çš„ç‚¹ï¼Œç»§ç»­æ‰¾ä¸‹ä¸€æ ¹
                remaining_points = np.delete(remaining_points, inliers, axis=0)
            else:
                # å¦‚æœå½“å‰æœ€å¤§çš„æ‹Ÿåˆç»“æœéƒ½ä¸ç¬¦åˆè¦æ±‚ï¼Œåˆ™åœæ­¢
                break

        if found_pipes_count == 0:
            self.log("å‡ ä½•æ ¡éªŒå¤±è´¥ï¼Œæœªå‘ç°ç¬¦åˆç‰©ç†ç‰¹å¾çš„åœ†æŸ±ä½“ã€‚")
        else:
            self.log(f"ä»»åŠ¡å®Œæˆï¼Œå…±å‘ç° {found_pipes_count} æ ¹ç®¡é“ã€‚")

    def add_pipe_to_view(self, pts, center, axis, radius, pipe_id):
        """å°†å•æ ¹ç®¡é“æ¸²æŸ“åˆ° 3D è§†å£ä¸­"""
        projs = np.dot(pts - center, axis)
        h = projs.max() - projs.min()
        true_center = center + axis * (projs.max() + projs.min()) / 2.0

        # ä¸ºæ¯æ ¹ç®¡éšæœºåˆ†é…ä¸€ä¸ªé¢œè‰²
        color = list(np.random.choice(range(256), size=3) / 255.0)

        self.plotter.add_mesh(pv.PolyData(pts), color=color, point_size=4, name=f"pipe_pts_{pipe_id}")
        geom = pv.Cylinder(center=true_center, direction=axis, radius=radius, height=h)
        self.plotter.add_mesh(geom, color=color, opacity=0.4, name=f"pipe_geom_{pipe_id}")
        self.plotter.reset_camera()


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = TunnelDetectorApp()
    window.show()
    sys.exit(app.exec_())